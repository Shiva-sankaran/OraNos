{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_points3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "class '__torch__.torch_sparse.storage.SparseStorage' already defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/shape3d/3D-ORS/utils/temp.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2243564947227d/home/shape3d/3D-ORS/utils/temp.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_points3d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretrained_api\u001b[39;00m \u001b[39mimport\u001b[39;00m PretainedRegistry\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_points3d/applications/pretrained_api.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39momegaconf\u001b[39;00m \u001b[39mimport\u001b[39;00m DictConfig\n\u001b[1;32m      6\u001b[0m \u001b[39m# Import building function for model and dataset\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_points3d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m instantiate_dataset\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_points3d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m instantiate_model\n\u001b[1;32m     10\u001b[0m \u001b[39m# Import BaseModel / BaseDataset for type checking\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_points3d/datasets/dataset_factory.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhydra\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_points3d\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseDataset\n\u001b[1;32m      8\u001b[0m log \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataset_class\u001b[39m(dataset_config):\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_points3d/datasets/base_dataset.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Compose, FixedPoints\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_geometric/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdebug\u001b[39;00m \u001b[39mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_geometric/data/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Data\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtemporal\u001b[39;00m \u001b[39mimport\u001b[39;00m TemporalData\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbatch\u001b[39;00m \u001b[39mimport\u001b[39;00m Batch\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_geometric/data/data.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m \u001b[39mimport\u001b[39;00m coalesce, SparseTensor\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (contains_isolated_nodes,\n\u001b[1;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnum_nodes\u001b[39;00m \u001b[39mimport\u001b[39;00m maybe_num_nodes\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_sparse/__init__.py:39\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m t_major \u001b[39m!=\u001b[39m major:\n\u001b[1;32m     32\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     33\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDetected that PyTorch and torch_sparse were compiled with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     34\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdifferent CUDA versions. PyTorch has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     35\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mt_major\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mt_minor\u001b[39m}\u001b[39;00m\u001b[39m and torch_sparse has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     36\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmajor\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mminor\u001b[39m}\u001b[39;00m\u001b[39m. Please reinstall the torch_sparse that \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     37\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatches your PyTorch install.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseStorage  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtranspose\u001b[39;00m \u001b[39mimport\u001b[39;00m t  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch_sparse/storage.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39massert\u001b[39;00m layout \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m layout \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m layout \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m layout\n\u001b[1;32m     20\u001b[0m \u001b[39m@torch\u001b[39;49m\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript\n\u001b[0;32m---> 21\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mSparseStorage\u001b[39;49;00m(\u001b[39mobject\u001b[39;49m):\n\u001b[1;32m     22\u001b[0m     _row: Optional[torch\u001b[39m.\u001b[39;49mTensor]\n\u001b[1;32m     23\u001b[0m     _rowptr: Optional[torch\u001b[39m.\u001b[39;49mTensor]\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch/jit/_script.py:924\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m _rcb \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m         _rcb \u001b[39m=\u001b[39m _jit_internal\u001b[39m.\u001b[39mcreateResolutionCallbackFromFrame(_frames_up \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 924\u001b[0m     _compile_and_register_class(obj, _rcb, qualified_name)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m    926\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    927\u001b[0m     \u001b[39m# this is a decorated fn, and we need to the underlying fn and its rcb\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sketch/lib/python3.8/site-packages/torch/jit/_script.py:64\u001b[0m, in \u001b[0;36m_compile_and_register_class\u001b[0;34m(obj, rcb, qualified_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m ast \u001b[39m=\u001b[39m get_jit_class_def(obj, obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     63\u001b[0m defaults \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mfrontend\u001b[39m.\u001b[39mget_default_args_for_class(obj)\n\u001b[0;32m---> 64\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_script_class_compile(qualified_name, ast, defaults, rcb)\n\u001b[1;32m     65\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39m_add_script_class(obj, qualified_name)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: class '__torch__.torch_sparse.storage.SparseStorage' already defined."
     ]
    }
   ],
   "source": [
    "from torch_points3d.applications.pretrained_api import PretainedRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n",
    "            batchsize, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(\n",
    "            batchsize, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False, channel=3):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = STN3d(channel)\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, N = x.size()\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        if D > 3:\n",
    "            feature = x[:, :, 3:]\n",
    "            x = x[:, :, :3]\n",
    "        x = torch.bmm(x, trans)\n",
    "        if D > 3:\n",
    "            x = torch.cat([x, feature], dim=2)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, N)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "\n",
    "def feature_transform_reguliarzer(trans):\n",
    "    d = trans.size()[1]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_model(nn.Module):\n",
    "    def __init__(self, k=40, normal_channel=True):\n",
    "        super(get_model, self).__init__()\n",
    "        if normal_channel:\n",
    "            channel = 6\n",
    "        else:\n",
    "            channel = 3\n",
    "        self.feat = PointNetEncoder(global_feat=True, feature_transform=True, channel=channel)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x, trans_feat\n",
    "\n",
    "class get_loss(torch.nn.Module):\n",
    "    def __init__(self, mat_diff_loss_scale=0.001):\n",
    "        super(get_loss, self).__init__()\n",
    "        self.mat_diff_loss_scale = mat_diff_loss_scale\n",
    "\n",
    "    def forward(self, pred, target, trans_feat):\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        mat_diff_loss = feature_transform_reguliarzer(trans_feat)\n",
    "\n",
    "        total_loss = loss + mat_diff_loss * self.mat_diff_loss_scale\n",
    "        return total_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9419e9a15ee727bb02dc7281f5771f5557cab91bce4c2ac74b9f318ff088450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
